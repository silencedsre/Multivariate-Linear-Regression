{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppose we have `n` features and `m` observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Index        | $X_{1}$       | $X_{2}$       | $X_{3}$       | .... | .... | $X_{n}$        | y        |\n",
    "|--------------|---------------|---------------|---------------|------|------|----------------|----------|\n",
    "| 1            | $x_{1}^{1} $  | $x_{2}^{1}$   | $x_{3}^{1}$   | ...  | ...  | $x_{n}^{1}$    | $y^{1}$  |\n",
    "| 2            | $x_{1}^{2}$   | $x_{2}^{2}$   | $x_{3}^{2}$   | ...  | ...  | $x_{n}^{2}$    | $y^{2}$  |\n",
    "| 3            | $x_{1}^{3}$   | $x_{2}^{3}$   | $x_{3}^{3}$   | ...  | ...  | $x_{n}^{3}$    | $y^{3}$  |\n",
    "| .            | .             | .             | .             | ...  | ...  | .              |          |\n",
    "| .            | .             | .             | .             | ...  | ...  | .              |          |\n",
    "| .            | .             | .             | .             | ...  | ...  | .              |          |\n",
    "| m            | $x_{1}^{m}$   | $x_{2}^{m}$   | $x_{3}^{m}$   | ...  | ...  | $x_{n}^{m}$    | $y^{m}$  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here `subscript` denotes feature and `superscript` denote observation number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the weights of matrix for n features is denoted by column vectors of shape [1, n]\n",
    "<br/>\n",
    "$$ \\beta = \\begin{bmatrix} \\beta_{1} & \\beta_{2} & \\beta_{3} & .... &  \\beta_{n} \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we need to calculate prediction for each observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\hat{y^1} = \\beta_{0} + \\beta_{1}x_{1}^{1} +  \\beta_{2}x_{2}^{1}  +  \\beta_{3}x_{3}^{1}  +  \\beta_{3}x_{3}^{1} + .... + \\beta_{n}x_{n}^{1}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y^2} = \\beta_{0} + \\beta_{1}x_{1}^{2} +  \\beta_{2}x_{2}^{2}  +  \\beta_{3}x_{3}^{2}  +  \\beta_{3}x_{3}^{2} + .... + \\beta_{n}x_{n}^{2}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y^3} =  \\beta_{0} +\\beta_{1}x_{1}^{3} +  \\beta_{2}x_{2}^{3}  +  \\beta_{3}x_{3}^{3}  +  \\beta_{3}x_{3}^{3} + .... + \\beta_{n}x_{n}^{3}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    " ..................\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    " ..................\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y^m} =  \\beta_{0} +\\beta_{1}x_{1}^{m} +  \\beta_{2}x_{2}^{m}  +  \\beta_{3}x_{3}^{m}  +  \\beta_{3}x_{3}^{m} + .... + \\beta_{n}x_{n}^{m}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In matrix form "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\begin{bmatrix} \\hat{y}^{1} \\\\ \\hat{y}^{2} \\\\ \\hat{y}^{3} \\\\ .. \\\\.. \\\\  \\hat{y}^{m} \\end{bmatrix} = \n",
    "\\begin{bmatrix} x_{1}^{1} & x_{2}^{1} & x_{3}^{1} & .... &  x_{n}^{1}\n",
    "           \\\\ x_{1}^{2} & x_{2}^{2} & x_{3}^{2} & .... &  x_{n}^{2}\n",
    "           \\\\ x_{1}^{3} & x_{2}^{3} & x_{3}^{3} & .... &  x_{n}^{3}\n",
    "           \\\\.... &.... & ... &.... &....\n",
    "           \\\\.... &.... & ... &.... &....\n",
    "            \\\\ x_{1}^{m} & x_{2}^{m} & x_{3}^{m} & .... &  x_{n}^{m}\n",
    "\\end{bmatrix}\n",
    "*\n",
    "\\begin{bmatrix} \\beta_{1} \\\\ \\beta_{2} \\\\ \\beta_{3} \\\\ .. \\\\.. \\\\  \\beta_{n} \\end{bmatrix}\n",
    "+ \\beta_{0}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation} \\hat{y} = X.\\beta^{T} + \\beta_{0} \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equivalent numpy implementation is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `y_hat = np.dot(X, B.T) + b`  \n",
    "Where \n",
    " $$ B = \\beta $$\n",
    " $$ b = \\beta_{0}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Mean Squared Error cost function is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ J(\\beta, \\beta_{0}) = \\frac{1}{2m}\\sum_{n=1}^{m}   (y - \\hat{y})^{2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equivalent numpy implementation is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cost = (1/(2*m))*np.sum((y-y_hat)**2)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just for confirmation let us take an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| y | $\\hat{y}$ | (y - $\\hat{y}$)^2 |\n",
    "|---|---------|-----------------|\n",
    "| 2 | 1       | 1               |\n",
    "| 4 | 2       | 4               |\n",
    "| 6 | 3       | 9               |\n",
    "|  |        | 14               |\n",
    "\n",
    "\\begin{equation} 14/3 = 4.67 \\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y=np.array([[2],\n",
    "           [4],\n",
    "           [6]])\n",
    "y_hat=np.array([[1],\n",
    "           [2],\n",
    "           [3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "4.666666666666667"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 73
    }
   ],
   "source": [
    "np.sum((y-y_hat)**2)/3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now lets calculate the gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have the loss function  defined as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ J(\\beta, \\beta_{0}) = \\frac{1}{2m}\\sum_{n=1}^{m}   (y - \\hat{y})^{2}   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where: $$ \\hat{y} = \\beta_{0} + X*\\beta^{T} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So:\n",
    "$$ \\frac {\\partial J(\\beta, \\beta_{0})}{\\partial \\beta_{0}} = \n",
    "\\frac{-1}{m}\\sum_{n=1}^{m}(y-\\hat{y}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again: $$ J(\\beta, \\beta_{0}) = \\frac{1}{2m}\\sum_{n=1}^{m}   (y - \\hat{y})^{2}   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac {\\partial J(\\beta, \\beta_{0})}{\\partial \\beta} = \\frac{-1}{m}\\sum_{n=1}^{m}   (y - \\hat{y}) * \\frac{\\partial (\\beta_{0} + X*\\beta^{T})}{\\partial \\beta} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\frac {\\partial J(\\beta, \\beta_{0})}{\\partial \\beta} = \n",
    "\\frac{-1}{m}\\sum_{n=1}^{m}(y-\\hat{y})*X * \\frac{\\partial \\beta^{T}}{\\partial \\beta} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $$ \\beta = \\begin{bmatrix} \\beta_{1} & \\beta_{2} & \\beta_{3} &.... & \\beta_{n} \\end{bmatrix}$$ \n",
    "\n",
    "and\n",
    "\n",
    "$$ \\beta^{T} = \\begin{bmatrix} \\beta_{1} \\\\ \\beta_{2} \\\\ \\beta_{3} \\\\.... \\\\ \\beta_{n} \\end{bmatrix}$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since: $$ \\frac{\\partial \\beta^{T}}{\\partial \\beta} = I $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just a side note for calculation of $$ \\frac{\\partial \\beta^{T}}{\\partial \\beta} $$\n",
    "where $$ \\beta = \\begin{bmatrix} \\beta_{1} & \\beta_{2} & \\beta_{3} &.... & \\beta_{n} \\end{bmatrix}$$ \n",
    "\n",
    "and\n",
    "\n",
    "$$ \\beta^{T} = \\begin{bmatrix} \\beta_{1} \\\\ \\beta_{2} \\\\ \\beta_{3} \\\\.... \\\\ \\beta_{n} \\end{bmatrix}$$ \n",
    "\n",
    "$$ \\frac{\\partial \\beta^{T}}{\\partial \\beta} = \\begin{bmatrix} \\frac{\\partial \\beta^{T}}{\\partial \\beta_{1}} & \\frac{\\partial \\beta^{T}}{\\partial \\beta_{2}} & \\frac{\\partial \\beta^{T}}{\\partial \\beta_{3}} & ....  & \\frac{\\partial \\beta^{T}}{\\partial \\beta_{n}}\\end{bmatrix} $$\n",
    "\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial \\beta^{T}}{\\partial \\beta} = \n",
    "\\begin{bmatrix} \n",
    "\\frac{\\partial \\beta_{1}}{\\partial \\beta_{1}} & \\frac{\\partial \\beta_{1}}{\\partial \\beta_{2}} & \\frac{\\partial \\beta_{1}}{\\partial \\beta_{3}} & ..&..& \\frac{\\partial \\beta_{1}}{\\partial \\beta_{n}}  \n",
    "\\\\  \n",
    "\\frac{\\partial \\beta_{2}}{\\partial \\beta_{1}} & \\frac{\\partial \\beta_{2}}{\\partial \\beta_{2}} & \\frac{\\partial \\beta_{2}}{\\partial \\beta_{3}} &..&..& \\frac{\\partial \\beta_{2}}{\\partial \\beta_{n}} \n",
    "\\\\ \n",
    "\\frac{\\partial \\beta_{2}}{\\partial \\beta_{1}} & \\frac{\\partial \\beta_{3}}{\\partial \\beta_{2}} & \\frac{\\partial \\beta_{3}}{\\partial \\beta_{3}} &..&..& \\frac{\\partial \\beta_{3}}{\\partial \\beta_{n}} \n",
    "\\\\ \n",
    ".. & .. & .. & ..  & .. &..\n",
    "\\\\\n",
    ".. & .. & .. & ..  & .. &..\n",
    "\\\\\n",
    "\\frac{\\partial \\beta_{n}}{\\partial \\beta_{1}} & \\frac{\\partial \\beta_{n}}{\\partial \\beta_{2}} & \\frac{\\partial \\beta_{n}}{\\partial \\beta_{3}} & ..&..& \\frac{\\partial \\beta_{n}}{\\partial \\beta_{n}}  \n",
    "\\end{bmatrix} $$\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial \\beta^{T}}{\\partial \\beta} = \n",
    "\\begin{bmatrix} \n",
    "1 & 0 & 0 & ..&..& 0  \n",
    "\\\\  \n",
    "0 & 1 & 0 &..&..& 0 \n",
    "\\\\ \n",
    "0 & 0 & 1 &..&..& 0 \n",
    "\\\\ \n",
    ".. & .. & .. & ..  & .. &..\n",
    "\\\\\n",
    ".. & .. & .. & ..  & .. &..\n",
    "\\\\\n",
    "0 & 0 & 0 & ..&..& 1  \n",
    "\\end{bmatrix} $$\n",
    "\n",
    "\n",
    "i.e $$  \\frac{\\partial \\beta^{T}}{\\partial \\beta} = I_{n*n} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since: $$ X_{m*n} * I_{n*n} = X $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So: $$ \\frac {\\partial J(\\beta, \\beta_{0})}{\\partial \\beta} = \n",
    "\\frac{-1}{m}\\sum_{n=1}^{m}(y-\\hat{y})*X $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of $$ \\sum_{n=1}^{m}(y-\\hat{y}) $$  `m rows and 1 cols [m, 1]`\n",
    "\n",
    "### Shape of `X is [m, n] ie m observations and n features`\n",
    "\n",
    "### Required shape of `dB is [1, n] `\n",
    "\n",
    "### [1, m] * [m, n] == [1, n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equivalent Numpy Implementation is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " `dB = (-1/m)* np.dot((y-y_hat).T, X)`\n",
    " <br/>\n",
    "  `db = (-1/m)*np.sum(y-y_hat)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just a side note for calculation of $$ \\frac{\\partial \\beta^{T}}{\\partial \\beta} $$\n",
    "where $$ \\beta = \\begin{bmatrix} \\beta_{1} & \\beta_{2} & \\beta_{3} &.... & \\beta_{n} \\end{bmatrix}$$ \n",
    "\n",
    "and\n",
    "\n",
    "$$ \\beta^{T} = \\begin{bmatrix} \\beta_{1} \\\\ \\beta_{2} \\\\ \\beta_{3} \\\\.... \\\\ \\beta_{n} \\end{bmatrix}$$ \n",
    "\n",
    "$$ \\frac{\\partial \\beta^{T}}{\\partial \\beta} = \\begin{bmatrix} \\frac{\\partial \\beta^{T}}{\\partial \\beta_{1}} & \\frac{\\partial \\beta^{T}}{\\partial \\beta_{2}} & \\frac{\\partial \\beta^{T}}{\\partial \\beta_{3}} & ....  & \\frac{\\partial \\beta^{T}}{\\partial \\beta_{n}}\\end{bmatrix} $$\n",
    "\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial \\beta^{T}}{\\partial \\beta} = \n",
    "\\begin{bmatrix} \n",
    "\\frac{\\partial \\beta_{1}}{\\partial \\beta_{1}} & \\frac{\\partial \\beta_{1}}{\\partial \\beta_{2}} & \\frac{\\partial \\beta_{1}}{\\partial \\beta_{3}} & ..&..& \\frac{\\partial \\beta_{1}}{\\partial \\beta_{n}}  \n",
    "\\\\  \n",
    "\\frac{\\partial \\beta_{2}}{\\partial \\beta_{1}} & \\frac{\\partial \\beta_{2}}{\\partial \\beta_{2}} & \\frac{\\partial \\beta_{2}}{\\partial \\beta_{3}} &..&..& \\frac{\\partial \\beta_{2}}{\\partial \\beta_{n}} \n",
    "\\\\ \n",
    "\\frac{\\partial \\beta_{2}}{\\partial \\beta_{1}} & \\frac{\\partial \\beta_{3}}{\\partial \\beta_{2}} & \\frac{\\partial \\beta_{3}}{\\partial \\beta_{3}} &..&..& \\frac{\\partial \\beta_{3}}{\\partial \\beta_{n}} \n",
    "\\\\ \n",
    ".. & .. & .. & ..  & .. &..\n",
    "\\\\\n",
    ".. & .. & .. & ..  & .. &..\n",
    "\\\\\n",
    "\\frac{\\partial \\beta_{n}}{\\partial \\beta_{1}} & \\frac{\\partial \\beta_{n}}{\\partial \\beta_{2}} & \\frac{\\partial \\beta_{n}}{\\partial \\beta_{3}} & ..&..& \\frac{\\partial \\beta_{n}}{\\partial \\beta_{n}}  \n",
    "\\end{bmatrix} $$\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial \\beta^{T}}{\\partial \\beta} = \n",
    "\\begin{bmatrix} \n",
    "1 & 0 & 0 & ..&..& 0  \n",
    "\\\\  \n",
    "0 & 1 & 0 &..&..& 0 \n",
    "\\\\ \n",
    "0 & 0 & 1 &..&..& 0 \n",
    "\\\\ \n",
    ".. & .. & .. & ..  & .. &..\n",
    "\\\\\n",
    ".. & .. & .. & ..  & .. &..\n",
    "\\\\\n",
    "0 & 0 & 0 & ..&..& 1  \n",
    "\\end{bmatrix} $$\n",
    "\n",
    "\n",
    "i.e $$  \\frac{\\partial \\beta^{T}}{\\partial \\beta} = I_{n*n} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-74-3d9ca5273f27>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    .def propagate(B, b, X, Y):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ],
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-74-3d9ca5273f27>, line 1)",
     "output_type": "error"
    }
   ],
   "source": [
    ".def propagate(B, b, X, Y):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    B: weights of size [1, X.shape[1]]\n",
    "    b: bias\n",
    "    X: matrix of observations and features size [X.shape[0], X.shape[1]]\n",
    "    Y: matrix of actual observation size [Y.shape[0], 1]\n",
    "    \n",
    "    returns:\n",
    "    grads: dict of gradients, dB of shape same as B and db of shape [1, 1].\n",
    "    cost: MSE cost of shape [m, 1]\n",
    "    \"\"\"\n",
    "    \n",
    "    ## m is no of observations ie rows of X\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    #Calculate hypothesis\n",
    "    y_hat = np.dot(X, B.T) + b\n",
    "    \n",
    "    y = Y.values.reshape(Y.shape[0],1)\n",
    "    \n",
    "    #Compute Cost\n",
    "    cost = (1/(2*m))*np.sum((y-y_hat)**2)\n",
    "    \n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "    dB = (-1/m)* np.dot((y-y_hat).T, X)\n",
    "    \n",
    "    db = -np.sum(y-y_hat)/m\n",
    "    \n",
    "    grads = {\"dB\": dB,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def optimize(B, b, X, Y, num_iterations, learning_rate):\n",
    "    \"\"\"\n",
    "    params:\n",
    "    B: weights of size [1, X.shape[1]]\n",
    "    b: bias\n",
    "    X: matrix of observations and features size [X.shape[0], X.shape[1]]\n",
    "    Y: matrix of actual observation size [Y.shape[0], 1]\n",
    "    num_iterations: number of iterations\n",
    "    learning_rate: learning rate\n",
    "    returns:\n",
    "    params: parameters B of shape [1, X.shape[1]] and bias\n",
    "    grads: dict of gradients, dB of shape same as B and db\n",
    "    costs:  MSE cost \n",
    "    \"\"\"\n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        \n",
    "        # Cost and gradient calculation call function propagate\n",
    "        grads, cost = propagate(B,b,X,Y)\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dB = grads[\"dB\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update parameters\n",
    "        B = B - learning_rate * dB\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        costs.append(cost)\n",
    "    \n",
    "    params = {\"B\": B,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dB\": dB,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def predict(B, b, X):\n",
    "    \"\"\":param\n",
    "    B: weights\n",
    "    b: bias\n",
    "    X: matrix of observations and features\n",
    "    \"\"\"\n",
    "  # Compute predictions for X\n",
    "    Y_prediction = np.dot(X, B.T) + b\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, num_iterations = 2000, learning_rate = 0.5):\n",
    "    \"\"\"\n",
    "    params: \n",
    "    X_train: X_train\n",
    "    Y_train: Y_train\n",
    "    X_test: X_test\n",
    "    Y_test: Y_test\n",
    "    \n",
    "    returns:\n",
    "    d: dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # initialize parameters with zeros \n",
    "    B = np.zeros(shape=(1, X_train.shape[1]))\n",
    "    b = 0\n",
    "    \n",
    "    # Gradient descent\n",
    "    parameters, grads, costs = optimize(B, b, X_train, Y_train, num_iterations, learning_rate)\n",
    "    \n",
    "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
    "    B = parameters[\"B\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Predict test/train set examples\n",
    "    Y_prediction_test = predict(B, b, X_test)\n",
    "    Y_prediction_train = predict(B, b, X_train)\n",
    "    \n",
    "    Y_train = Y_train.values.reshape(Y_train.shape[0], 1)\n",
    "    Y_test = Y_test.values.reshape(Y_test.shape[0], 1)\n",
    "\n",
    "   # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"B\" : B, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('USA_Housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df.drop(['Address'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "pre_process = preprocessing.StandardScaler()\n",
    "\n",
    "df_norm = (df - df.mean()) / (df.max() - df.min())\n",
    "\n",
    "# Putting feature variable to X\n",
    "X = df_norm[['Avg. Area Income','Avg. Area House Age','Avg. Area Number of Rooms','Avg. Area Number of Bedrooms','Area Population']]\n",
    "\n",
    "# Putting response variable to y\n",
    "y = df_norm['Price']\n",
    "\n",
    "\n",
    "X = pd.DataFrame(pre_process.fit_transform(X))\n",
    "\n",
    "#random_state is the seed used by the random number generator, it can be any integer.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7 ,test_size = 0.3, random_state=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# y_train.reshape(y_train.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model1 = model(X_train=X_train, Y_train=y_train, X_test=X_test, Y_test=y_test, num_iterations = 500, learning_rate = 0.001)\n",
    "\n",
    "model2 = model(X_train=X_train, Y_train=y_train, X_test=X_test, Y_test=y_test, num_iterations = 500, learning_rate = 0.01)\n",
    "\n",
    "model3 = model(X_train=X_train, Y_train=y_train, X_test=X_test, Y_test=y_test, num_iterations = 500, learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot([i for i in range(500)], model1['costs'])\n",
    "plt.plot([i for i in range(500)], model2['costs'])\n",
    "plt.plot([i for i in range(500)], model3['costs'])\n",
    "\n",
    "plt.gca().legend(('alpha 0.001','alpha 0.01', 'alpha 0.1'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# model4 = model(X_train=X_train, Y_train=y_train, X_test=X_test, Y_test=y_test, num_iterations = 10, learning_rate = 0.01)\n",
    "\n",
    "# model5 = model(X_train=X_train, Y_train=y_train, X_test=X_test, Y_test=y_test, num_iterations = 100, learning_rate = 0.01)\n",
    "\n",
    "# model6 = model(X_train=X_train, Y_train=y_train, X_test=X_test, Y_test=y_test, num_iterations = 1000, learning_rate = 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}